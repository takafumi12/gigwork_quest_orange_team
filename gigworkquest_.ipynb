{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "gigworkquest_.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takafumi12/gigwork_quest_orange_team/blob/hanada/gigworkquest_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJGREXazJK-j"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# digitsデータを使うためにimportする\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision\n",
        "from torchvision import transforms as transforms"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOhdB0tTJK_R",
        "outputId": "d0483952-76be-46ef-e154-51598e505bc4"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayCRzNhkJ3Qz"
      },
      "source": [
        "# import zipfile\r\n",
        "\r\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Data/gigwork_quest/train.zip') as existing_zip:\r\n",
        "#     existing_zip.extractall('/content/drive/MyDrive/Data/gigwork_quest')\r\n",
        "\r\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Data/gigwork_quest/test.zip') as existing_zip:\r\n",
        "#     existing_zip.extractall('/content/drive/MyDrive/Data/gigwork_quest')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWMXsenvquXt"
      },
      "source": [
        "# 画像の読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz5JyzN1k40z",
        "outputId": "d4ebf22d-18a9-4831-a61e-ba69e3101623"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "PATH = '/content/drive/'"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOdeedc4k44T"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Data/gigwork_quest/train_master.tsv',sep='\\t')\r\n",
        "y = np.array(df[\"label_id\"])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xd4v5frjFJ_"
      },
      "source": [
        "import glob\r\n",
        "import os.path as osp\r\n",
        "import torch.utils.data as data\r\n",
        "from torchvision import models, transforms\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "\r\n",
        "class ImageTransform():\r\n",
        "    \"\"\"\r\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\r\n",
        "    画像のサイズをリサイズし、色を標準化する。\r\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\r\n",
        "\r\n",
        "\r\n",
        "    Attributes\r\n",
        "    ----------\r\n",
        "    resize : int\r\n",
        "        リサイズ先の画像の大きさ。\r\n",
        "    mean : (R, G, B)\r\n",
        "        各色チャネルの平均値。\r\n",
        "    std : (R, G, B)\r\n",
        "        各色チャネルの標準偏差。\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, resize, mean, std):\r\n",
        "        self.data_transform = {\r\n",
        "            'train': transforms.Compose([\r\n",
        "                # transforms.RandomResizedCrop(\r\n",
        "                #     resize, scale=(0.5, 1.0)),  # データオーギュメンテーション\r\n",
        "                # transforms.RandomHorizontalFlip(),  # データオーギュメンテーション\r\n",
        "                transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\r\n",
        "                transforms.ToTensor(),  # テンソルに変換\r\n",
        "                transforms.Normalize(mean, std)  # 標準化\r\n",
        "            ]),\r\n",
        "            'test': transforms.Compose([\r\n",
        "                transforms.Resize(resize),  # リサイズ\r\n",
        "                transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\r\n",
        "                transforms.ToTensor(),  # テンソルに変換\r\n",
        "                transforms.Normalize(mean, std)  # 標準化\r\n",
        "            ])\r\n",
        "        }\r\n",
        "\r\n",
        "    def __call__(self, img, phase='train'):\r\n",
        "        \"\"\"\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        phase : 'train' or 'val'\r\n",
        "            前処理のモードを指定。\r\n",
        "        \"\"\"\r\n",
        "        return self.data_transform[phase](img)\r\n",
        "\r\n",
        "\r\n",
        "def make_datapath_list(phase=\"train\"):\r\n",
        "    \"\"\"\r\n",
        "    データのパスを格納したリストを作成する。\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    phase : 'train' or 'val'\r\n",
        "        訓練データか検証データかを指定する\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    path_list : list\r\n",
        "        データへのパスを格納したリスト\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    rootpath = PATH + \"MyDrive/Data/gigwork_quest/\"\r\n",
        "    target_path = osp.join(rootpath+phase+'/*.png')\r\n",
        "    print(target_path)\r\n",
        "\r\n",
        "    path_list = []  # ここに格納する\r\n",
        "\r\n",
        "    # globを利用してサブディレクトリまでファイルパスを取得する\r\n",
        "    for path in glob.glob(target_path):\r\n",
        "        path_list.append(path)\r\n",
        "\r\n",
        "    return path_list\r\n",
        "\r\n",
        "\r\n",
        "class HymenopteraDataset(data.Dataset):\r\n",
        "    \"\"\"\r\n",
        "    画像のDatasetクラス。PyTorchのDatasetクラスを継承。\r\n",
        "\r\n",
        "    Attributes\r\n",
        "    ----------\r\n",
        "    file_list : リスト\r\n",
        "        画像のパスを格納したリスト\r\n",
        "    transform : object\r\n",
        "        前処理クラスのインスタンス\r\n",
        "    phase : 'train' or 'test'\r\n",
        "        学習か訓練かを設定する。\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, file_list, y, transform=None, phase='train'):\r\n",
        "        self.file_list = file_list  # ファイルパスのリスト\r\n",
        "        self.y = y #画像の正解ラベル\r\n",
        "        self.transform = transform  # 前処理クラスのインスタンス\r\n",
        "        self.phase = phase  # train or valの指定\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        '''画像の枚数を返す'''\r\n",
        "        return len(self.file_list)\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        '''\r\n",
        "        前処理をした画像のTensor形式のデータとラベルを取得\r\n",
        "        '''\r\n",
        "\r\n",
        "        # index番目の画像をロード\r\n",
        "        img_path = self.file_list[index]\r\n",
        "        img = Image.open(img_path)  # [高さ][幅][色RGB]\r\n",
        "\r\n",
        "        # 画像の前処理を実施\r\n",
        "        img_transformed = self.transform(\r\n",
        "            img, self.phase)  # torch.Size([3, 224, 224])\r\n",
        "\r\n",
        "        return img_transformed, y[index]\r\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdKjdhM2jFNi",
        "outputId": "01e0596e-4408-49ab-9299-67ef50b34e77"
      },
      "source": [
        "from torch.utils.data.dataset import Subset\r\n",
        "\r\n",
        "# 1.3節で作成したクラスを同じフォルダにあるmake_dataset_dataloader.pyに記載して使用\r\n",
        "#from utils.dataloader_image_classification import ImageTransform, make_datapath_list, HymenopteraDataset\r\n",
        "\r\n",
        "#import sys\r\n",
        "#sys.path.append('/content/drive/My Drive/Colab/my_project/my_modules')\r\n",
        "\r\n",
        "# 画像へのファイルパスのリストを作成する\r\n",
        "train_list = make_datapath_list(phase=\"train\")\r\n",
        "# test_list = make_datapath_list(phase=\"test\")\r\n",
        "\r\n",
        "# Datasetを作成する\r\n",
        "size = 224\r\n",
        "mean = (0.485, 0.456, 0.406)\r\n",
        "std = (0.229, 0.224, 0.225)\r\n",
        "\r\n",
        "train_dataset = HymenopteraDataset(\r\n",
        "    file_list=train_list, y=y, transform=ImageTransform(size, mean, std), phase='train')\r\n",
        "\r\n",
        "# test_dataset = HymenopteraDataset(\r\n",
        "#     file_list=test_list, transform=ImageTransform(size, mean, std), phase='test')\r\n",
        "\r\n",
        "# print(len(train_dataset)) # 231\r\n",
        "# print(len(val_dataset)) # 59\r\n",
        "# print(len(test_dataset)) # 213\r\n",
        "\r\n",
        "# # DataLoaderを作成する\r\n",
        "# batch_size = 32\r\n",
        "\r\n",
        "# train_dataloader = torch.utils.data.DataLoader(\r\n",
        "#     train_dataset, batch_size=batch_size, shuffle=True)\r\n",
        "\r\n",
        "# val_dataloader = torch.utils.data.DataLoader(\r\n",
        "#     val_dataset, batch_size=batch_size, shuffle=False)\r\n",
        "\r\n",
        "# test_dataloader = torch.utils.data.DataLoader(\r\n",
        "#     test_dataset, batch_size=1, shuffle=False)\r\n",
        "\r\n",
        "# # 辞書オブジェクトにまとめる\r\n",
        "# dataloaders_dict = {\"train2\": train_dataloader, \"val2\": val_dataloader}"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Data/gigwork_quest/train/*.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V0w7z-EjFTU"
      },
      "source": [
        "#train_testに分割\r\n",
        "n_samples = len(train_dataset)\r\n",
        "train_size = int(len(train_dataset) * 0.8)\r\n",
        "val_size = n_samples - train_size\r\n",
        "\r\n",
        "trainset, testset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSpD1T8_jFY_",
        "outputId": "36b135ad-baea-409f-b9a4-dffc1ad693f9"
      },
      "source": [
        "print(len(trainset),len(testset))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38100 9525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fXAUWvjJK_k",
        "outputId": "86b416fd-cc8b-4578-fc4b-02b3d12520fb"
      },
      "source": [
        "classes = tuple([i for i in range(20)])\n",
        "classes"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn346a24JK_m"
      },
      "source": [
        "train_loader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNZryFJMJK_n"
      },
      "source": [
        "## 転移学習\n",
        "---\n",
        "今回はVGG16を利用しました。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FIRZAc0JK_o"
      },
      "source": [
        "# Enter your code here\n",
        "model_ft2 = models.vgg16(pretrained=True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7KvtfRrJK_p"
      },
      "source": [
        "# パラメーターを学習させないようにしている\n",
        "# Enter your code here\n",
        "for param in model_ft2.parameters():\n",
        "    param.require_grad = False"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcImy_amJK_q"
      },
      "source": [
        "# 最後の一層だけ書き換えて、最後の一層だけ学習させる\n",
        "# Enter your code here\n",
        "model_ft2.fc = nn.Linear(in_features=512, out_features=len(classes), bias=True)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRrnAKqNJK_r",
        "outputId": "e5af3270-50d1-4951-ee01-c6782ae0ac74"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "print(loss_func)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CrossEntropyLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7GWxXIBJK_t"
      },
      "source": [
        "optimizer = optim.SGD(model_ft2.parameters(), lr=0.001)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3zwHugbJK_t"
      },
      "source": [
        "model_ft2 = model_ft2.to(device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsNtHZA9JK_u"
      },
      "source": [
        "param = {\n",
        "    'trainloader': train_loader,\n",
        "    'valloader': test_loader,\n",
        "    'net': model_ft2,\n",
        "    'optimizer': optimizer,\n",
        "    'lossfunc': loss_func,\n",
        "    'epochs': 5,\n",
        "    'device': device\n",
        "    }"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dfqHyieJK_v"
      },
      "source": [
        "def training(trainloader, valloader, net, optimizer, lossfunc, epochs, device):\n",
        "    train_loss_track = []\n",
        "    test_loss_track = []\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        running_loss = 0\n",
        "        running_train_loss = 0\n",
        "        running_test_loss = 0\n",
        "\n",
        "        # 学習モード\n",
        "        net.train()\n",
        "        for step, batch  in enumerate(trainloader, 1):\n",
        "            # device = \"cuda\"の場合、GPUにデータを転送する\n",
        "            xx, yy = batch[0].to(device), batch[1].to(device)\n",
        "            # 最後に計算した各パラメーターの勾配を初期化する\n",
        "            optimizer.zero_grad()\n",
        "            # フォワード計算を行う\n",
        "            y_pred = net(xx)\n",
        "            # 誤差関数を使ってギャップの計測\n",
        "            loss = lossfunc(y_pred, yy)\n",
        "            # 誤差逆伝播法を使って自動微分\n",
        "            loss.backward()\n",
        "            # パラメーターを更新\n",
        "            optimizer.step()\n",
        "            # 学習データを使って損失を計算\n",
        "            running_loss += loss.item()\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "            # 100 iterationごとにlossを出力\n",
        "            if step % 100 == 0:\n",
        "                print('[{:d} epoch, {:5d} iter] train/loss: {}'.format(epoch, step, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "        # エポックが終了したら平均損失を計算\n",
        "        train_loss_track.append(running_train_loss / len(train_loader))\n",
        "\n",
        "        # 評価（evaluation）モード\n",
        "        net.eval()\n",
        "        # 勾配計算用のパラメータを保存しない\n",
        "        with torch.no_grad():\n",
        "            for step, batch in enumerate(valloader, 1):\n",
        "                # device = \"cuda\"の場合、GPUにデータを転送する\n",
        "                xx_test, yy_test = batch[0].to(device), batch[1].to(device)\n",
        "                # 予測値を計算\n",
        "                y_pred = net(xx_test)\n",
        "                # 誤差関数を使ってギャップの計測\n",
        "                test_loss = lossfunc(y_pred, yy_test)\n",
        "                # テストデータを使って損失を計算\n",
        "                running_test_loss += test_loss.item()\n",
        "        # 誤差をトラッキング\n",
        "        test_loss_track.append(running_test_loss / len(valloader))\n",
        "        print('val/loss: {}'.format(running_test_loss / len(valloader)))\n",
        "    return net, train_loss_track, test_loss_track"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "a0EgGKs3JK_w",
        "outputId": "0405d242-4d47-4657-e42c-cb89642511c6"
      },
      "source": [
        "model_ft2, train_loss_track, test_loss_track = training(**param)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-569dded416f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ft2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_track\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_track\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-f24fefffabb5>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(trainloader, valloader, net, optimizer, lossfunc, epochs, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# 誤差逆伝播法を使って自動微分\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;31m# パラメーターを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Ju9WSKJK_x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvkhnvUsJK_x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zptqzHPlJK_y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea9JcXBPJK_y"
      },
      "source": [
        "## 交差エントロピー誤差の推移"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2HJsGVBJK_z"
      },
      "source": [
        "plt.plot(train_loss_track)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C10J84Q-JK_0"
      },
      "source": [
        "plt.plot(test_loss_track)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L1B8MKjJK_0"
      },
      "source": [
        "def calculate_accuracy(testloader, net):\n",
        "    true = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = np.array([])\n",
        "    all_preds = np.array([])\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for test_xx, test_yy in testloader:\n",
        "            \n",
        "            # device = \"cuda\"の場合、GPUにデータを転送する\n",
        "            test_xx = test_xx.to(device)\n",
        "            test_yy = test_yy.to(device)\n",
        "\n",
        "            outputs = net(test_xx)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            all_labels = np.append(all_labels, test_yy.cpu().data.numpy())\n",
        "            all_preds = np.append(all_preds, predicted.cpu().numpy())\n",
        "            \n",
        "            total += test_yy.size(0)\n",
        "            true += (predicted == test_yy).sum().item()\n",
        "    print('Accuracy: {:.2f} %'.format(100 * float(true/total)))\n",
        "\n",
        "    return all_labels, all_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e0QikzCJK_1"
      },
      "source": [
        "all_labels, all_preds = calculate_accuracy(test_loader, model_ft2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVwc0cdBJK_1"
      },
      "source": [
        "## testデータで混同行列を作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy8fPo2qJK_2"
      },
      "source": [
        "def plot_conf_mat(all_labels, all_preds):\n",
        "    labels = np.unique(all_labels)\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=labels)\n",
        "    cm_labeled = pd.DataFrame(cm, columns=labels, index=labels)\n",
        "    return cm_labeled\n",
        "\n",
        "plot_conf_mat(all_labels, all_preds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}